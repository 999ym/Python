6.1) 데이터 정제하기 입문

6.1.1 데이터 분석 과정 소개

데이터 분석과정
1) 데이터 정제 : 필터링, 이상치/결측값/중복값 제거 및 대체, 자료형 보정 등
2) 데이터 결합 : 병합(merge), 연결(concat) 등
3) 열 가공 : 범주화, 새로운 특성(feature)등
4) 그룹화 : 그룹별 열 가공, 그룹 집계, 시계열 그룹 집계

6.1.2 데이터 정제하기란?
- 데이터 분석을 수행하기전 데이터의 품질을 개선하는 과정
- 주로 필터링, 이상치, 결측값 등의 제거 및 대체, 자료형 보정등을 수행
- 필터링 : 데이터에서 특정 조건을 만족하는 데이터만 추출하는 작업
- 결측값 : 값이 누락된 것
- 이상치 : 데이터의 일반적인 경향과 크게 벗어난 것
- 중복값 : 중복 기재된 데이터
- 결측값, 이상치, 중복값은 데이터의 특성을 왜곡시키거나 정확도를 떨어뜨리기에 제거 또는 대체하는 것이 좋다.
- 오기 등의 이유로 자료형이 잘못 설정되거나 여러가지 자료형이 혼합될 때가 많다. 예를들어 수치형 데이터가 문자열로 잘못 지정될경우 연산을 수행할 수 없다.
- 데이터 정제에는 여러 과정이 더 있으며, 데이터 정제는 데이터 분석의 결과의 정확도와 신뢰도를 높이는 필수 과정이다.

6.2) 정렬
- 데이터의 정렬 함수: sort_values/ sort_index
- sort_values : 특정 열을 기준으로 정렬을 수행
- sort_index : 인덱스나 컬럼즈를 기준으로 정렬

6.2.1 단일 열을 기준으로 정렬하기(sort_values)

* 데이터 프레임이나 시리즈의 정렬을 수행하는 함수
df.sort_values(by, ascending=True)
by : 정렬의 기준이 될 열을 지정한다. 복수라면 리스트로 묶어 입력한다.
ascending : 정렬 방식을 오름차순 또는 내림차순으로 지정한다. 기본값은 오름차순이다.

* 실습 예제 코드 
import pandas as pd
data1=[[60,84,80,19],[77,62,95,17],[61,84,72,15],[75,65,95,18]]
cols=['국어','영어','수학','나이']
df1=pd.DataFrame(data1,index=list('ABCD'),columns=cols)

* 국어 열을 기준으로 오름차순 정렬하기
df1.sort_values(by='국어') # 함수의 원본인 df1은 변경되지 않는다.

6.2.2 오름차순과 내림차순

* 국어 열을 기준으로 내림차순으로 정렬하기
df1.sort_values(by='국어', ascending=False)

6.2.3 복수의 열을 기준으로 정렬하기

* 영어 열로 오름차순 정렬하되, 동점일 때는 나이 열로 오름차순 정렬
df1.sort_values(by=['영어','나이'])

* 영어 열로 내림차순 정렬하되, 동점일 때는 나이열로 오름차순으로 정렬
df1.sort_values(by=['영어','나이'], ascending=[False,True])

6.2.4 인덱스나 컬럼즈를 기준으로 정렬하기(sort_index)

*인덱스나 컬럼즈를 기준으로 정렬을 수행하는 함수
df.sort_index(axis=0, level=None, ascending=True)
axis : 인덱스가 기준인지 컬럼즈가 기준인지 지정한다. 기본값은 0 = 인덱스
level : 멀티 인덱스를 보유할 때 정렬의 기준이 되는 레벨을 지정한다.
ascending : 정렬 방식을 오름차순 또는 내림차순으로 지정한다.

* 인덱스를 기준으로 알파벳 역순으로 정렬
df1.sort_index(ascending=False)
df1.sort_index(axis=1) # 컬럼즈 기준으로 정렬

6.3) 필터링
- 대규모 raw데이터 수집시 필터링을 통해 데이터를 원하는 범위로 좁혀 데이터 분석의 효율성을 높일 수 있다. 판다스는 주로 불리언 인덱싱으로 필터링을 수행한다.

6.3.1 불리언 인덱싱이란?

* 6.2.1 의 실습예제 코드에서 A행과 C행의 데이터만 가져오고 싶다면, loc인덱서를 이용 할 수 있다. 그런데 키 이름대신 불 자료형 리스트를 입력해도 인덱싱이 수행된다.
df1.loc[['A','C'],:] #KEY 인덱싱
df1.loc[[True,False,True,False]] #불리언 인덱싱, True,False 배열의 길이는 데이터의 길이와 반드시 일치해야한다. 당연히 데이터 길이만큼 긴 배열을 입력해야하는 불리언 인덱싱을 직접 입력하는 방식을 잘 사용하지는 않고, 비교 연산 결과인 시리즈를 이용해 사용한다.

- df1.loc[df1['국어']<70] : 국어 열이 70보다 작다는 비교 연산으로 시리즈를 불 시리즈로 만들고, 불리언 인덱싱을 수행한 후 True인 행을 인덱싱한다.

6.3.2 단일 요건 불리언 인덱싱

- 불리언 인덱싱은 키 슬라이싱의 원칙을 준용한다.
- 행을 대상으로 불리언 인덱싱을 수행할 때는 대괄호 인덱서와 loc 인덱서 모두 사용할 수 있다. 열을 대상으로 불리언 인덱싱을 수행할 때는 loc인덱서만 사용한다. iloc 인덱서도 제한된 상황에서 사용할 수 있으나 대부분 불가능하다.
* 행의 불리언 인덱싱을 수행할 때 : 대괄호 인덱서, loc 인덱서
* 열의 불리언 인덱싱을 수행할 때 : loc 인덱서
* 불리언 인덱싱을 포함해 행과 열을 동시에 인덱싱 할 때 : loc 인덱서

* 국어 점수가 70점보다 낮은 행을 필터링 '
df1['국어']<70
df1.loc[df1['국어']<70]

* 조건문도 불 시리즈이기 때문에 변수로 지정할 수 있다.
cond1=df1['국어']<70
df1[cond1]

* 국어 점수가 70점보다 낮은 행의 국어, 수학 열만 필터링 
df1.loc[df1['국어']<70,['국어','수학']]

* A가 80점 이상 받은 과목의 전체 성적만 필터링
df1.loc[:,df1.loc['A']>=80]

6.3.3 다중 요건 불리언 인덱싱

- 여러가지 조건으로 필터링을 수행하려면 여러 개의 조건문이 필요하다. 여러 개의 조건문은 모두 불 시리즈이므로 논리 연산을 수행해 하나의 조건문으로 만들 수 있다.

 * 국어 점수가 70점보다 낮으면서 수학 점수가 75점보다 높은 행 필터링
df1[(df1['국어']<70)&(df1['수학']>75)]
ㄴ 연산자로 여러 조건문을 생성해 불리언 인덱싱을 수행할 때, 각 조건문을 반드시 소괄호로 묶어야 한다. 이는 파이썬의 문법 규칙 때문이다. 조건문을 변수로 지정하면 가독성이 향상된다.

* 위 코드의 조건문을 변수로 지정하면 가독성이 향상된다
cond1 =df1['국어']<70
cond2 =df1['수학']>75
df1[cond1&cond2]

6.3.4 불 자료형 객체를 생성하는 함수 

- 비교 연산 외에 함수를 사용해도 불 시리즈를 생성할 수 있다. 
1) isna, isnull :NaN이면 True, 아니면 False 
2) notna, notnull : NaN이면 False, 아니면 True
3) isin: 지정한 값에 포함되면 True, 아니면 False
4) between : 두 값 사이에 존재하면 True, 아니면 False
5) duplicated : 중복이면 True, 아니면 False

* NaN은 NaN과 같지 않다
float('nan')==float('nan')
#결과는 False / 이런 이유로 isna 함수가 필요하다.

* 실습 예제 코드
import pandas as pd
data2 = {'반':['1반','4반','5반','2반','1반','3반'],
         '국어':[60,77,61,75,92,90],
         '영어':[84,62,84,65,81,90],
         '수학':[80,float('nan'),72,95,float('nan'),81]    
}
df2=pd.DataFrame(data2)

* 수학 열 에서 NaN을 확인
df2['수학'].isna()

- 판다스에서 isna와 isnull 함수는 완전히 동일한 기능을 한다.
- notna와 notnull 함수는 isna와 반대로 결측값에 False를 반환하고 값이 존재하면 True를 반환한다.
- ~s.isna()와 s.notna()는 같다
- isna로 불리언 인덱싱을 수행하면, 결측값이 존재하는 행을 삭제할 수도 있다. 
- 단순히 결측값이 있는 행을 삭제할 때는 dropna 함수가 더욱 간편하다.
- isna 함수는 전체 데이터에서 NaN의 개수를 탐색, 여러 조건문과 함께 사용하여 불리언 인덱싱을 수행할때 주로 사용한다.

* 수학 열에서 NaN의 개수를 확인
df2['수학'].isna().sum()

* 수학 열이 NaN이 아니거나 국어가 90점 이상인 데이터를 필터링
cond1= df2['수학'].notna()
cond2 = df2['국어']>=90
df2[cond1&cond2]

- 논리 연산으로 A 또는 B 둘 중 하나에 해당하는지 확인할 수 있다. 그러나 논리 연산으로 확인해야하는 값의 개수가 많아지면 그만큼의 조건문이 함께 생성되는 불편함이 생긴다. 
- 확인을 원하는 값들을 배열로 만들어 isin 함수에 입력하면 내가 원하는 값인지 아닌지 True나 False로 손쉽게 반환한다.

* 데이터 프레임이나 시리즈의 각 셀의 값이 특정 배열에 포함되는지 여부 확인하는 함수
df.isin(values)
values : 포함 여부를 확인할 기준 배열을 입력한다.

* 1반,2반,3반 중 하나에 속하는 데이터만 필터링
cond5 = df2['반'].isin(['1반','2반','3반'])
df2[cond5]


* 시리즈의 각 셀이 주어진 두 값 사이에 존재하는지 확인 하는 함수
s.between(left, right, inclusive='both')
left,right : 좌측 경계와 우측 결계를 각각 입력한다.
inclusive : 경계의 포함 여부를 지정한다. 기본값은 'both'이고 양쪽 경계가 모두 포함된다
- between 함수는 시리즈에만 적용한다. 
- 시리즈의 각 셀이 주어진 두 값 사이에 있는지 True 또는 False로 반환하는 함수이다. 

6.3.5 특정 열의 값을 기준으로 데이터의 일부만 가져오기(nlargest, nsmallest)

* 특정 열의 값을 기준으로 데이터의 일부만 가져오는 함수, nlargest 함수는 기준 열의 값이 높은 순으로 요구하는 행만큼, nsmallest 함수는 기준 열의 값이 낮은 순으로 요구하는 행만큼 가져온다.
df.nlargest(n, columns, keep='first')
n : 상위 몇 개의 행을 가져올지 정수로 지정한다.
columns : 정렬 기준이 되는 열을 지정한다.
keep: 동점이 존재할 때, 어떤 행을 가져올지 결정한다. 기본값은 첫 행만 가져오는 'first'이며, 'last'또는 'all'도 지정이 가능하다.

* 실습 예제 코드 
import pandas as pd
data2 = {'반':['1반','4반','5반','2반','1반','3반'],
         '국어':[60,77,61,75,92,90],
         '영어':[84,62,84,65,81,90],
         '수학':[80,float('nan'),72,95,float('nan'),81]    
}
df2=pd.DataFrame(data2)

* 국어 점수가 하위인 4명의 데이터만 필터링
df2.nsmallest(4,columns='국어')

- 매개변수 keep으로 동점을 처리하는 방식을 지정할 수 있다. 
1) first : 동점인 행 중에 가장 첫 행을 가져온다.
2) last : 동점인 행 중에 가장 마지막 행을 가져온다.
3) all : 동점인 행은 모두 가져온다.

* 영어 점수가 상위인 2명의 데이터 추출(동점자는 모두 추출)
df2.nlargest(2,columns='영어',keep='all')

6.3.6 무작위로 데이터 추출하기(sample)

* 데이터 프레임에서 무작위로 행을 추출하는 함수
df.sample(n=None, frac=None, random_state=None)
n : 추출할 행의 개수를 정수로 지정한다. 매개변수 frac과 동시 사용할 수 없다.
frac : 추출할 비율을 0과 1사이의 실수로 지정한다. 매개변수 n과 동시에 사용할 수 없다. 0하면 하나도 안나옴. 1하면 전체가 다 재배열됨. 0.5로 지정하면 반만 재배열되며 나머지는 아예 출력이 안됨.
random_state : 난수 고정을 위해 시드를 지정한다. 시드 정수 별로 고정 값이 달라진다.

* df2에서 무작위로 3명의 데이터 추출
df2.sample(3) # 시행마다 다른 결과가 반환된다.

* df2 전체를 랜덤하게 재배열(난수 고정)
df2.sample(frac=1,random_state=20) 
ㄴ 무작위로 추출하지만 결과를 고정하고 싶다면, 매개변수 random_state로 시드를 부여하자. 전체를 무작위로 재배열하면서 결과를 고정하자. 
frac=1을 입력하면 전체가 재배열되고 시드로 정수를 부여하면 결과가 고정된다.

엑셀 예제 4 ) OECD 국가 GDP 데이터에서 원하는 데이터 추출하기

"1인당 GDP, 소속 대륙, GDP 상위 국가 등을 기준으로 데이터를 추출하자."

* OECD 국가 GDP 통계 엑셀 파일에서 데이터 프레임 불러오기
import pandas as pd
pd.options.display.max_rows=6 # 6행까지만 출력 코드
url1='https://github.com/panda-kim/book1/blob/main/08GDP.xlsx?raw=true'
df_gdp=pd.read_excel(url1)

* 1인당 GDP가 8만 달러 이상인 데이터 추출
cond1=df_gdp['1인당 GDP($)']>=80000
df_gdp[cond1]

* 아시아, 남미, 오세아니아의 데이터만 추출
cond1=df_gdp['대륙'].isin(['아시아','남미','오세아니아'])
df_gdp[cond1]

* GDP 상위 3개 국가 데이터 추출
df_gdp.nlargest(3,columns='GDP(10억$)')

6.4) 결측값 처리하기1

6.4.1 결측값 확인하기(isna)

* 결측값 처리 실습 예제 코드
import pandas as pd
data=[[88,66,None],[None,None,69],[69,82,None],[71,89,98]]
df=pd.DataFrame(data,index=list('ABCD'),columns=['국어','영어','수학'])

* df의 각 열에 결측값이 얼마나 존재하는지 확인
df.isna().sum()

6.4.2 결측값을 포함한 데이터 삭제하기(dropna)

* 결측값(null)이 있는 열이나 행을 삭제하는 함수
df.dropna(axis=0, how='any', subset=None)
axis : 행을 삭제하는지 열을 삭제하는지 지정한다. 기본값은 0이고 결측값이 존재하는 행을 삭제한다.
how : 어떤 기준으로 NaN을 보유한 열이나 행을 어떻게 삭제할지 지정한다. 'any'는 하나라도 NaN이 존재하면 삭제하고, 'all'은 모두 NaN일 때 삭제한다. 기본값은 any.
subset : 지정된 열에 NaN이 존재할 때만 삭제한다.

*NaN이 존재하는 행을 모두 삭제
df.dropna() 

* 수학 열에 NaN이 존재하는 행만 삭제
df.dropna(subset='수학')
ㄴ 다른열에 NaN이 있어도 수학열에만 NaN이 없으면 남김 

6.4.3 결측값 대체하기(fillna)

* 결측값을 지정한 값으로 대체하는 함수
df.fillna(value=None)
value : NaN을 대체할 값을 지정한다. 입력하는 값의 종류와 함수를 적용하는 객체에 따라 다양한 방식으로 대체된다. 

* df의 NaN을 0으로 대체하기
df.fillna(0)

- 입력하는 값의 종류와 함수하는 객체에 따라 다양한 방식으로 대체된다.
1. value가 단일 값(스칼라) 
ㄴ시리즈에  fillna를 적용할 경우 : 단일 값으로 NaN을 대체
ㄴ데이터프레임에  fillna를 적용할 경우 : 단일 값으로 NaN을 대체
2.value가 시리즈(혹은 딕셔너리)
ㄴ시리즈에  fillna를 적용할 경우 : 인덱스가 동일한 값으로 NaN을 대체
ㄴ데이터프레임에  fillna를 적용할 경우 : 브로드 캐스팅
3. value가 데이터 프레임
ㄴ시리즈에  fillna를 적용할 경우 : 불가능
ㄴ데이터프레임에  fillna를 적용할 경우 : 인덱스와 컬럼즈가 모두 동일한 값으로 NaN을 대체

* 수학 열의 결측값을 국어 열로 대체
df['수학'].fillna(df['국어'])

*영어 열은 0, 수학 열은 30으로 결측값 대체
df.fillna({'영어':0,'수학':30}) 

* 과목별 최저점으로 NaN을 대체
df.fillna(df.min())
ㄴ 딕셔너리뿐 아니라 시리즈도 매퍼로 사용 가능. 최저점 시리즈 적용

6.5 이상치와 중복 데이터 처리

6.5.1 이상치 처리하기(clip)

- 이상치: 모집단의 일반적인 경향에서 크게 벗어난 데이터
- 이상치의 처리는 간단하지 않아 다양한 방법을 사용한다.

* 상한선이나 하한선으로 임곗값을 적용해 이상치(outlier)를 처리하는 함수
df.clip(lower=None, upper=None)
lower : 최솟값으로 적용할 임곗값을 입력한다. 배열을 입력하면 열마다 다르게 적용한다.
upper : 최댓값으로 적용할 임곗값을 입력한다. 배열을 입력하면 열마다 다르게 적용한다.

* clip 함수 실습 예제 코드
import pandas as pd
data1=[[89,4,74],[29,46,83],[40,19,60],[29,91,76]]
df1=pd.DataFrame(data1, index=list('ABCD'), columns=['국어','영어','수학'])

* 상한선과 하한선으로 임곗값을 각각 20과 80으로 적용
df1.clip(lower=20,upper=80)
ㄴ clip 함수에 배열을 입력하면 열마다 다른 임곗값이 지정된다. clip 함수는 간편함이 장점이다.
ㄴ clip 함수만으로는 복잡한 이상치 처리에 한계가 있으므로 불리언 마스킹을 비롯한 여러가지 판다스 기법과 함수를 활용한다.

6.5.2 중복 데이터 확인 및 제거(duplicated, drop_duplicates)

* 중복 데이터를 확인하거나 삭제하는 함수
df.drop_duplicates(subset=None, keep='first')
subset : 중복을 확인할 열을 지정한다. 기본값은 모든 열의 값이 동일할 때 중복으로 처리된다.
keep : 중복일때 어떤 행을 유지할지 지정한다. 'first'가 기본값이며, 동일한 데이터가 존재하더라도 첫번째 행은 유지하고 두 번째 행부터 중복 데이터로 처리한다.

* 중복 데이터 처리 실습 예제 코드
import pandas as pd
data={'회차':[1,1,1,2,2],
      '이름':['김판다','김판다','강승주','조민영','김판다'],
      '점수':[680,680,880,620,750]    
}
df=pd.DataFrame(data)
ㄴ df의 첫번째 행과 두 번째 행은 완전히 동일한 데이터이다. 이 때 사용하는 함수가 dulicated 함수이다.

* 중복 데이터 확인
df.duplicated()
ㄴ 첫 번째 행과 두 번째 행은 서로 중복되는 데이터이다. 그런데 두 번째 행만 True로 반환된다. 동일한 데이터라도 처음 등장한 데이터는 중복이 아니며 두 번째 등장한 동일 데이터부터 중복으로 처리한다. 이런 중복 처리 방식이 keep='first' 방식이며 기본값이다.

* 중복 데이터 삭제
df.drop_duplicates()
ㄴ 중복된 데이터가 삭제되는데, 두 번째 행만 삭제된다. 중복된 데이터라도 그 중 하나의 데이터는 남겨야 하기에 keep의 기본값이 'first'로 설정된다.

-매개변수 keep과 중복 처리 방식
1) keep='first' : 동일한 데이터 중, 첫 번째 데이터를 제외하고 모두 중복으로 처리(기본값)
2) keep='last' : 동일한 데이터 중, 마지막 데이터를 제외하고 모두 중복으로 처리
3) keep= False : 동일한 데이터는 모두 중복으로 처리

6.5.3 중복 데이터 처리 함수의 활용

- 중복 데이터 처리 함수들은 완전히 중복된 데이터를 처리하는 용도뿐만 아니라 데이터를 필터링 하는데도 사용된다.
- 기본값은 모든 열의 데이터가 동일해야 중복, subset으로 열을 지정할 경우 특정 열의 데이터만 중복이어도 중복으로 처리한다.

* df의 이름 열로만 중복을 결정해 중복 데이터 삭제
df.drop_duplicates('이름') #df.drop_duplicates()는 모든 열이 일치해야했으나 이제는 이름이 '김판다'인 행이 전부 삭제되었다.

- 특정 열에서만 중복을 판단하고 keep 방식을 활용하면 여러 가지 필터링이 수행된다.

* keep을 활용해 각 사람의 마지막 성적을 필터링
df.drop_duplicates('이름',keep='last') #마지막 '김판다'가 출력된다.

* keep을 활용해 시험에 한 번만 응시한 사람의 성적만 필터링
df.drop_duplicates('이름',keep=False) # 중복을 전부 제거하기 때문에 '김판다'는 전부 사라진다.

6.6) 자료형 변환과 소수점 처리

- 판다스에서 주로 사용되는 자료형
1) float : 실수(부동소수점)
2) int : 정수
3) str : 문자열
4) bool : 불 
5) datetime : 시계열
6) category : 범주형

6.6.1 여러 가지 자료형으로 변환하기(astype)

* 데이터 프레임이나 시리즈의 자료형을 변환하는 함수
df.astype(dtype)
dtype : 변환할 자료형을 지정한다. 매퍼를 입력하면 열마나 서로 다른 자료형으로 변환한다.

* 자료형 변환 실습 예제 코드
import pandas as pd
data1=[[8.2,9,'17','1'],[7.1,9,'18','2'],
       [9.3,7,'18','3'],[7.8,7,'19','-']]
df1=pd.DataFrame(data1, columns=['실수','정수','문자열1','문자열2'])

* df1의 자료형을 dtypes 속성으로 파악하기
df1.dtypes

* df1의 자료형을 문자열(str)로 변환하기
df1.astype('str') #원본은 변환되지 않는다.

* 문자열로 변환된 df1의 결과 자료형 확인하기
df1.astype('str').dtypes
ㄴ df1의 모든열이 object 자료형으로 변환된 것이 확인된다. 판다스에서는 문자열 또는 문자열이 섞인 자료형은 object로 표현된다.
ㄴ 매퍼를 입력하면 열마나 다른 자료형으로 변환된다.

* 매퍼를 입력해 열마다 다른 자료형으로 변환한 뒤 자료형 확인하기
df1.astype({'실수':'int','정수':'str'}).dtypes
''' 결과
실수	int64
정수	object
문자열1	object
문자열2	object
'''

* 실수 열을 정수 자료형으로 변환하기
df1['실수'].astype('int') # 자료형이 실수일때 astype 함수로 정수 자료형으로 변환하면 소수점 이하가 탈락되어 정수로 변환된다. 이는 자연스럽게 버림의 효과를 얻는다. 
''' 결과
	실수
0	8
1	7
2	9
3	7
'''
6.6.2 수치형으로 변환하기(to_numeric)

* 단일 값 또는 1차원 배열의 자료형을 수치형으로 변환하는 함수
pd.to_numeric(arg, errors='raise')
arg : 변환할 대상을 지정한다. 스칼라 또는 1차원 배열을 입력한다.
errors :  변환할 수 없는 데이터를 처리하는 방법을 지정한다. 변환할 수 없는 데이터를 만났을 때 기본값인 'raise'는 에러가 발생한다.  'coerce'는 변환할 수 없는 데이터를 NaN으로 변환하고 변환을 완료한다. 'ignore'은 변환하지 않고 원본을 유지하며, 변환하는 다른 데이터도 전혀 변환하지 않는다. 대부분은 'coerce'를 사용한다.
 
* 수치형으로 바꿀 수 없는 문자열이 포함되었을 때 수치형으로 변환하기
import pandas as pd
data1=[[8.2,9,'17','1'],[7.1,9,'18','2'],
       [9.3,7,'18','3'],[7.8,7,'19','-']]
df1=pd.DataFrame(data1, columns=['실수','정수','문자열1','문자열2'])
pd.to_numeric(df1['문자열2'],errors='coerce')
'''결과
	문자열2
0	1.0
1	2.0
2	3.0
3	NaN
'''
ㄴ 문자열 2에는 숫자로는 변환할 수 없는 데이터 '-'이 존재하므로 df1 전체를 정수나 실수 자료형으로 변환하는 것을 astype 함수로 수행할 수 없다.

* 데이터 프레임 전체에 to_numeric 함수 적용하기
df1.apply(pd.to_numeric,errors='coerce')
ㄴ to_numeric 함수는 시리즈 또는 스칼라에만 적용가능하기 때문에 데이터 프레임에 적용하기 위해서는 apply를 사용해야한다.

- astype과 to_numeric을 이용하여 수치형으로 변환할 때의 차이
astype
ㄴ 데이터 프레임에 적용 가능 : O
ㄴ 실수의 정수 변환 가능  : O (소수점 이하를 버린다)
ㄴ 메서드 형태로 적용한다 : O
ㄴ 변환할 수 없는 데이터 처리 : 에러발생
 
to_numeric
ㄴ 데이터 프레임에 적용 가능 : X (apply를 이용해야한다.)
ㄴ 실수의 정수 변환 가능  : X (각 수치마다 실수, 정수 다르게 나타난다)
ㄴ 메서드 형태로 적용한다 : X (pd 함수 형태)
ㄴ 변환할 수 없는 데이터 처리 : NaN으로 변환 (errors='coerce')

6.6.3 소수점 처리하기

* 데이터 프레임이나 시리즈를 반올림하는 함수
df.round(decimals=0)
decimals : 소수점 자릿수를 지정한다. 기본값은 0이고 소수점 첫째 자리에서 반올림을 수행한다.

* 반올림 실습 예제 코드
import pandas as pd
data2=[[1.025,2.249],[3.923,4.035],[5.418,6.736]]
df2=pd.DataFrame(data2, index=list('ABC'), columns=['col1','col2'])

* df2를 소수점 셋째 자리에서 반올림
df2.round(2)
''' 결과
전 
	col1	col2
A	1.025	2.249
B	3.923	4.035
C	5.418	6.736

후
	col1	col2
A	1.02	2.25
B	3.92	4.04
C	5.42	6.74

'''
ㄴ round 함수를 적용하고 2를 입력하면 소수점 셋째 자리에서 반올림을 수행한다. 소수점 셋째 자리가 0~4일 때는 버림을 수행하고, 6~9일때는 올림을 수행한다. 소수점 셋째 자리가 5이면 소수점 둘째자리가 홀수라면 올림, 짝수라면 버림을 수행한다.

* 출력 옵션으로 소수점 둘째 자리까지 표시
pd.options.display.float_format='{:.2f}'.format
df2
ㄴ 실제 데이터 변환없이 출력 옵션만 조정하는 방법이다. 

- 이외 소수점 올림과 버림도 소수점 처리 방법으로 가능하지만, 거의 사용되지 않아 판다스와 관련한 함수는 없다. 필요시 넘파이 함수를 사용하여 올림과 버림을 수행한다. 
올림은 np.ceil, 버림은 np.trunc로 가능하다. 판다스는 넘파이의 어레이 기반으로 만들어진 클래스이므로 많은 넘파이 함수가 호환된다.

6.7) 치환과 매핑

- 치환과 매핑을 이용하면 데이터의 일관성이 높아지며 데이터의 의미가 더 쉽게 이해된다. 또한, 데이터를 효율적으로 관리, 분석하는데 도움이 된다.

* 데이터 프레임이나 시리즈의 각 셀을 치환하는 함수
df.replace(to_replace=None, value=None, regex=False)
to_replace : 이전 값을 입력한다. 이전 값과 새로운 값의 매퍼도 입력 가능하다.
value : 새로운 값을 입력한다.
regex : 정규 표현식 사용 여부를 입력한다.

* 치환 실습 예제 코드
import pandas as pd
data= {'홈팀':['서독','대한민국','브라질','소련','대한민국'],
       '원정팀':['대한민국','서독','소련','브라질','브라질'],
       '홈팀골':[3,1,4,2,0],'원정팀골':[0,2,1,2,2]    
}
data1={'old':['서독','소련'],'new':['독일','러시아']}
df=pd.DataFrame(data)
df1=pd.DataFrame(data1)

* 서독을 독일로 치환
df.replace('서독','독일')
''' 결과 
전)
	홈팀	원정팀	홈팀골	원정팀골
0	서독	대한민국	3	0
1	대한민국	서독	1	2
2	브라질	소련	4	1
3	소련	브라질	2	2
4	대한민국	브라질	0	2
후)
	홈팀	원정팀	홈팀골	원정팀골
0	독일	대한민국	3	0
1	대한민국	독일	1	2
2	브라질	소련	4	1
3	소련	브라질	2	2
4	대한민국	브라질	0	2
'''

* regex=True로 셀의 일부로 치환 # 기본 값은 셀 전체의 값만 치환
df.replace('대한민','한',regex=True)
''' 결과 
전)
	홈팀	원정팀	홈팀골	원정팀골
0	서독	대한민국	3	0
1	대한민국	서독	1	2
2	브라질	소련	4	1
3	소련	브라질	2	2
4	대한민국	브라질	0	2
후)
	홈팀	원정팀	홈팀골	원정팀골
0	서독	한국	3	0
1	한국	서독	1	2
2	브라질	소련	4	1
3	소련	브라질	2	2
4	한국	브라질	0	2
'''

* 서독과 소련을 EU로 치환
df.replace(['서독','소련'],'EU')

* 서독을 독일로 치환하고 소련을 러시아로 치환
df.replace({'서독':'독일','소련':'러시아'})
''' 결과 
전)
	홈팀	원정팀	홈팀골	원정팀골
0	서독	대한민국	3	0
1	대한민국	서독	1	2
2	브라질	소련	4	1
3	소련	브라질	2	2
4	대한민국	브라질	0	2
후)
	홈팀	원정팀	홈팀골	원정팀골
0	독일	대한민국	3	0
1	대한민국	독일	1	2
2	브라질	러시아	4	1
3	러시아	브라질	2	2
4	대한민국	브라질	0	2
'''

* 데이터 프레임으로 매퍼(시리즈)를 만들어 치환하기
m= df1.set_index('old')['new']
df.replace(m)

6.7.2 데이터 매핑하기(map)

* 시리즈나 인덱스 클래스의 매핑을 수행하는 함수
s.map(func)
func : 함수, 시리즈, 딕셔너리 등의 매퍼를 입력한다.

* 매핑 실습 예제 코드
import pandas as pd
s = pd.Series(['사과','바나나','바나나','포도','사과'])

* 사과는 0, 바나나는 1, 포도는 2로 매핑하기
dict1={'사과':0,'바나나':1,'포도':2}
s.map(dict1)
'''결과
	0
0	0
1	1
2	1
3	2
4	0
'''

6.7.3 replace 함수와 map 함수의 차이

- 치환 : 일부를 변환하는 것
- 매핑 : 전체를 변환하는 것
-> 전체를 치환한다면 매핑과 치환은 같다.

* replace로 바꿔서 수행하기
import pandas as pd
data= {
       '홈팀':['서독','대한민국','브라질','소련','대한민국'],
       '원정팀':['대한민국','서독','소련','브라질','브라질'],
       '홈팀골':[3,1,4,2,0],'원정팀골':[0,2,1,2,2]    
}
data1={'old':['서독','소련'],'new':['독일','러시아']}
df=pd.DataFrame(data)
df1=pd.DataFrame(data1)
s = pd.Series(['사과','바나나','바나나','포도','사과'])
dict1={'사과':0,'바나나':1,'포도':2}
s.map(dict1)
-> s.replace(dict1) 

* 사과만 0으로 매핑하기
import pandas as pd
s = pd.Series(['사과','바나나','바나나','포도','사과'])
dict2={'사과':0}
s.map(dict2)
''' 결과
	0
0	0.00
1	NaN
2	NaN
3	NaN
4	0.00
'''
ㄴ 일부만 치환할때는 replace 함수와 map 함수의 차이가 크다. 둘은 수행하지 않는 값에 대한 처리가 다르다. replace 함수는 치환하지 않는 값을 그대로 두지만, map함수는 NaN 값으로 바꾼다.

* 위의 코드를 replace 함수로 수행해 map함수와의 차이 확인하기
import pandas as pd
s = pd.Series(['사과','바나나','바나나','포도','사과'])
dict2={'사과':0}
s.replace(dict2)
''' 결과
	0
0	0.00
1	바나나
2	바나나
3	포도
4	0.00
'''
ㄴ replace 함수는 치환하지 않는 바나나와 포도를 그대로 반환한다.

* 사과는 0, 나머지는 전부 1로 매핑하기
import pandas as pd
s = pd.Series(['사과','바나나','바나나','포도','사과'])
dict2={'사과':0}
s.map(dict2).fillna(1).astype('int')

- map과 replace 함수의 차이
map
ㄴ 데이터 프레임에 적용이 가능한가? X
ㄴ 시리즈에 적용이 가능한가? O
ㄴ 인덱스 클래스에 적용이 가능한가? O
ㄴ 임무가 수행되지 않는 값의 처리는? NaN을 반환 
ㄴ 셀의 일부 문자열을 치환 가능한가? X

replace
ㄴ 데이터 프레임에 적용이 가능한가? O
ㄴ 시리즈에 적용이 가능한가? O
ㄴ 인덱스 클래스에 적용이 가능한가? X
ㄴ 임무가 수행되지 않는 값의 처리는? 원래의 값 반환
ㄴ 셀의 일부 문자열을 치환 가능한가? O (regex=True 일 때)

엑셀 예제5) 미국 레스토랑 고객의 팁 데이터 정제하기

1. tip 열에 존재하는 '-'을 NaN으로 대체하고 tip 열을 수치형 자료형으로 변환하자
2. time 열의 데이터를 간결하게 Lunch를 0, Dinner를 1로 매핑하자
3. smoker 열의 결측값을 남성일 때 Yes, 여성일 때 No로 대체하자.

* 미국 레스토랑 고객의 팁 엑셀 파일에서 데이터 프레임 불러오기
import pandas as pd
pd.options.display.max_rows=6 #6행까지만 출력
url2='https://github.com/panda-kim/book1/blob/main/09tips.xlsx?raw=true'
df_tips=pd.read_excel(url2)

* info 함수로 데이터 프레임 확인 하기
df_tips.info()

* tip열을 실수 자료형으로 변환하기
 df_tips['tip']=pd.to_numeric(df_tips['tip'],errors='coerce')

* time열의 Lunch를 0, Dinner를 1로 매핑하기
df_tips['time']=df_tips['time'].map({'Lunch':0,'Dinner':1})

* smoker 열의 결측값을 여자일 때 No, 남자일때는 Yes로 대체하기
m2={'Female':'No','Male':'Yes'}
df_tips['smoker']=df_tips['smoker'].fillna(df_tips['gender'].map(m2))